{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c34806f-5ad3-4230-885d-0079190b0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a12c8e0-9e05-49fd-9fe8-bd958403a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/areem/cleaned_reviews_w_lang.pkl', 'rb') as file:\n",
    "    reviews = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc879c1-6187-4107-b8ef-d447e9d33dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>cleaned_comments</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419</td>\n",
       "      <td>38924112</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>11308465</td>\n",
       "      <td>Marcela</td>\n",
       "      <td>Having the opportunity of arriving to Alexandr...</td>\n",
       "      <td>Having the opportunity of arriving to Alexandr...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419</td>\n",
       "      <td>44791978</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>9580285</td>\n",
       "      <td>Marco</td>\n",
       "      <td>We have no enough words to describe how beauty...</td>\n",
       "      <td>We have no enough words to describe how beauty...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1419</td>\n",
       "      <td>45957133</td>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>38394721</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>The listing was exceptional and an even better...</td>\n",
       "      <td>The listing was exceptional and an even better...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1419</td>\n",
       "      <td>67295154</td>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>3515044</td>\n",
       "      <td>Shaun</td>\n",
       "      <td>Alexandra's home was amazing and in such a nea...</td>\n",
       "      <td>Alexandra's home was amazing and in such a nea...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1419</td>\n",
       "      <td>177702208</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>13987100</td>\n",
       "      <td>Kate</td>\n",
       "      <td>Beautiful home. Very comfortable and clean. Pe...</td>\n",
       "      <td>Beautiful home. Very comfortable and clean. Pe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id         id       date  reviewer_id reviewer_name  \\\n",
       "0        1419   38924112 2015-07-19     11308465       Marcela   \n",
       "1        1419   44791978 2015-08-29      9580285         Marco   \n",
       "2        1419   45957133 2015-09-07     38394721        Andrea   \n",
       "3        1419   67295154 2016-03-28      3515044         Shaun   \n",
       "4        1419  177702208 2017-08-03     13987100          Kate   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Having the opportunity of arriving to Alexandr...   \n",
       "1  We have no enough words to describe how beauty...   \n",
       "2  The listing was exceptional and an even better...   \n",
       "3  Alexandra's home was amazing and in such a nea...   \n",
       "4  Beautiful home. Very comfortable and clean. Pe...   \n",
       "\n",
       "                                    cleaned_comments language  \n",
       "0  Having the opportunity of arriving to Alexandr...       en  \n",
       "1  We have no enough words to describe how beauty...       en  \n",
       "2  The listing was exceptional and an even better...       en  \n",
       "3  Alexandra's home was amazing and in such a nea...       en  \n",
       "4  Beautiful home. Very comfortable and clean. Pe...       en  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d070d91a-52d0-4b25-90de-6bfaa49e68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.fillna('none', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63e50e0-c97a-4473-b522-ea10fcce2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03104a9e-d480-428d-9e7d-f9fdec7a0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean(reviews):\n",
    "    letters_only=BeautifulSoup(review).get_text()\n",
    "    letters_only = re.sub('[^a-zA-Z0-9]', ' ', letters_only)\n",
    "    letters_only = letters_only.lower()\n",
    "    words= letters_only.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "965223bb-bc4f-414c-9012-3dc0dee3f847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/459355 [00:00<?, ?it/s]C:\\Users\\areem\\AppData\\Local\\Temp\\ipykernel_21592\\893645082.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  letters_only=BeautifulSoup(review).get_text()\n",
      "100%|██████████| 459355/459355 [02:28<00:00, 3086.29it/s]\n"
     ]
    }
   ],
   "source": [
    "all_reviews = []\n",
    "for review in tqdm(reviews['comments']):\n",
    "    all_reviews.append(clean(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "396909d8-ab75-4cad-a7ab-f75fd9e2d3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alexandra incredible host stay beautiful home checked us offered help anyway could house described great neighbourhood everything easy access friends thoroughly enjoyed would recommend everyone say thank'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19756e86-2b7d-47a8-b8a3-5112da26c167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexandra was such an incredible host during our stay in her beautiful home. She checked up on us and offered to help in anyway she could. The house was just as described and in such a great neighbourhood, everything was very easy to access. My friends and I thoroughly enjoyed ourselves and would recommend it to everyone. All we can say is thank you!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['comments'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19eebf60-91ed-4d94-8daf-9448c0c9e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5856f2c-786a-450a-b7b8-baf7c9c5a565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_0</th>\n",
       "      <th>tfidf_1</th>\n",
       "      <th>tfidf_2</th>\n",
       "      <th>tfidf_3</th>\n",
       "      <th>tfidf_4</th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_6</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_8</th>\n",
       "      <th>tfidf_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_491</th>\n",
       "      <th>tfidf_492</th>\n",
       "      <th>tfidf_493</th>\n",
       "      <th>tfidf_494</th>\n",
       "      <th>tfidf_495</th>\n",
       "      <th>tfidf_496</th>\n",
       "      <th>tfidf_497</th>\n",
       "      <th>tfidf_498</th>\n",
       "      <th>tfidf_499</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf_0  tfidf_1  tfidf_2  tfidf_3  tfidf_4  tfidf_5  tfidf_6  tfidf_7  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   tfidf_8   tfidf_9  ...  tfidf_491  tfidf_492  tfidf_493  tfidf_494  \\\n",
       "0      0.0  0.000000  ...        0.0   0.000000        0.0   0.000000   \n",
       "1      0.0  0.000000  ...        0.0   0.000000        0.0   0.000000   \n",
       "2      0.0  0.144606  ...        0.0   0.155968        0.0   0.131945   \n",
       "3      0.0  0.000000  ...        0.0   0.000000        0.0   0.000000   \n",
       "4      0.0  0.000000  ...        0.0   0.000000        0.0   0.000000   \n",
       "\n",
       "   tfidf_495  tfidf_496  tfidf_497  tfidf_498  tfidf_499  listing_id  \n",
       "0        0.0        0.0   0.000000        0.0   0.000000      1419.0  \n",
       "1        0.0        0.0   0.000000        0.0   0.000000      1419.0  \n",
       "2        0.0        0.0   0.210229        0.0   0.088418      1419.0  \n",
       "3        0.0        0.0   0.000000        0.0   0.000000      1419.0  \n",
       "4        0.0        0.0   0.000000        0.0   0.000000      1419.0  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word', max_features=500)\n",
    "reviews_tfidf = tfidfvectorizer.fit_transform(all_reviews)\n",
    "reviews_tfidf = reviews_tfidf.toarray()\n",
    "reviews_tfidf = pd.DataFrame(data=reviews_tfidf, columns=['tfidf_' + str(i) for i in range(500)])\n",
    "reviews_tfidf['listing_id'] = reviews['listing_id']\n",
    "\n",
    "reviews_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cdfd7f7-2179-46c4-8151-56c473e03224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>tfidf_0</th>\n",
       "      <th>tfidf_1</th>\n",
       "      <th>tfidf_2</th>\n",
       "      <th>tfidf_3</th>\n",
       "      <th>tfidf_4</th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_6</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_490</th>\n",
       "      <th>tfidf_491</th>\n",
       "      <th>tfidf_492</th>\n",
       "      <th>tfidf_493</th>\n",
       "      <th>tfidf_494</th>\n",
       "      <th>tfidf_495</th>\n",
       "      <th>tfidf_496</th>\n",
       "      <th>tfidf_497</th>\n",
       "      <th>tfidf_498</th>\n",
       "      <th>tfidf_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8077.0</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.008867</td>\n",
       "      <td>0.013830</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.047658</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.025924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26654.0</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27423.0</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>0.031207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30931.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id   tfidf_0   tfidf_1   tfidf_2   tfidf_3  tfidf_4   tfidf_5  \\\n",
       "0      1419.0  0.000000  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "1      8077.0  0.006660  0.000000  0.003850  0.000734      0.0  0.008198   \n",
       "2     26654.0  0.008015  0.000000  0.004169  0.000000      0.0  0.000000   \n",
       "3     27423.0  0.004981  0.010609  0.009874  0.010113      0.0  0.012130   \n",
       "4     30931.0  0.000000  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "\n",
       "    tfidf_6   tfidf_7   tfidf_8  ...  tfidf_490  tfidf_491  tfidf_492  \\\n",
       "0  0.000000  0.035742  0.000000  ...    0.00000   0.000000   0.025995   \n",
       "1  0.008867  0.013830  0.004177  ...    0.00000   0.005644   0.006118   \n",
       "2  0.008113  0.006933  0.000000  ...    0.00641   0.000000   0.003784   \n",
       "3  0.002758  0.008087  0.009691  ...    0.00000   0.000000   0.010411   \n",
       "4  0.000000  0.000000  0.000000  ...    0.00000   0.000000   0.000000   \n",
       "\n",
       "   tfidf_493  tfidf_494  tfidf_495  tfidf_496  tfidf_497  tfidf_498  tfidf_499  \n",
       "0   0.000000   0.021991   0.000000   0.000000   0.035038   0.000000   0.035336  \n",
       "1   0.004677   0.047658   0.000608   0.000000   0.001355   0.005286   0.025924  \n",
       "2   0.005866   0.030423   0.000000   0.000000   0.000000   0.000000   0.055716  \n",
       "3   0.010304   0.014296   0.000000   0.003552   0.000000   0.007691   0.031207  \n",
       "4   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.164793  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by listing and get average per listing\n",
    "\n",
    "# Average the features for each listings\n",
    "reviews_tfidf_avg= reviews_tfidf.groupby('listing_id').mean().reset_index()\n",
    "reviews_tfidf_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6c198de-83e3-41ee-9e1a-a4698bcd166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(analyzer='word', ngram_range=(1,2), max_features=500)\n",
    "reviews_count1 = vectorizer1.fit_transform(all_reviews)\n",
    "reviews_count1= reviews_count1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f9a2ba0-dc55-444a-9667-ca7ceb3b505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count1 = pd.DataFrame(data=reviews_count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82076e39-7b55-4be7-9cb3-8d4935132103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  490  491  492  493  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    1    0  ...    1    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   494  495  496  497  498  499  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    1    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_count1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2fbf476-815b-4b45-8fd9-d9f6016fc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count1['listing_id'] = reviews['listing_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b041a7e-bb94-4d42-9744-24a53e8ee8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count1.columns=['count_' + str(i) for i in range(reviews_count1.shape[1]-1)]+['listing_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1abcc746-34b2-4217-b797-043b30b319b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>count_6</th>\n",
       "      <th>count_7</th>\n",
       "      <th>count_8</th>\n",
       "      <th>count_9</th>\n",
       "      <th>...</th>\n",
       "      <th>count_491</th>\n",
       "      <th>count_492</th>\n",
       "      <th>count_493</th>\n",
       "      <th>count_494</th>\n",
       "      <th>count_495</th>\n",
       "      <th>count_496</th>\n",
       "      <th>count_497</th>\n",
       "      <th>count_498</th>\n",
       "      <th>count_499</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_0  count_1  count_2  count_3  count_4  count_5  count_6  count_7  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   count_8  count_9  ...  count_491  count_492  count_493  count_494  \\\n",
       "0        0        0  ...          0          0          0          0   \n",
       "1        0        0  ...          0          0          0          0   \n",
       "2        1        0  ...          0          0          0          0   \n",
       "3        0        0  ...          0          0          0          0   \n",
       "4        0        0  ...          0          0          0          0   \n",
       "\n",
       "   count_495  count_496  count_497  count_498  count_499  listing_id  \n",
       "0          0          0          0          0          0        1419  \n",
       "1          0          0          0          0          0        1419  \n",
       "2          1          0          0          0          0        1419  \n",
       "3          0          0          0          0          0        1419  \n",
       "4          0          0          0          0          0        1419  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_count1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4308eb0-f521-4169-85a5-a6861db7405c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>count_6</th>\n",
       "      <th>count_7</th>\n",
       "      <th>count_8</th>\n",
       "      <th>...</th>\n",
       "      <th>count_490</th>\n",
       "      <th>count_491</th>\n",
       "      <th>count_492</th>\n",
       "      <th>count_493</th>\n",
       "      <th>count_494</th>\n",
       "      <th>count_495</th>\n",
       "      <th>count_496</th>\n",
       "      <th>count_497</th>\n",
       "      <th>count_498</th>\n",
       "      <th>count_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8077</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.011976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26654</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27423</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id   count_0   count_1   count_2   count_3   count_4   count_5  \\\n",
       "0        1419  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1        8077  0.017964  0.000000  0.011976  0.005988  0.053892  0.053892   \n",
       "2       26654  0.023810  0.000000  0.023810  0.000000  0.023810  0.023810   \n",
       "3       27423  0.074074  0.037037  0.037037  0.000000  0.074074  0.000000   \n",
       "4       30931  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    count_6   count_7   count_8  ...  count_490  count_491  count_492  \\\n",
       "0  0.166667  0.000000  0.166667  ...   0.166667   0.000000   0.000000   \n",
       "1  0.059880  0.005988  0.023952  ...   0.275449   0.000000   0.035928   \n",
       "2  0.047619  0.023810  0.095238  ...   0.023810   0.023810   0.000000   \n",
       "3  0.074074  0.111111  0.074074  ...   0.148148   0.037037   0.000000   \n",
       "4  0.000000  0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "\n",
       "   count_493  count_494  count_495  count_496  count_497  count_498  count_499  \n",
       "0   0.000000   0.000000   0.333333   0.000000   0.000000   0.166667   0.000000  \n",
       "1   0.005988   0.023952   0.197605   0.023952   0.023952   0.035928   0.011976  \n",
       "2   0.047619   0.023810   0.309524   0.095238   0.047619   0.000000   0.000000  \n",
       "3   0.111111   0.037037   0.555556   0.111111   0.074074   0.074074   0.000000  \n",
       "4   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the features per listing\n",
    "reviews_count_avg = reviews_count1.groupby('listing_id').mean().reset_index()\n",
    "\n",
    "reviews_count_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7dd6fd5-8ad6-4f9a-ab29-fb08d383d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enough words describe beautyful cozy alexandra house every detail tasteful functional kids stunned seen toys room tree house loved home thank', 'listing exceptional even better experience person house beautiful accommodating group anything could needed available experience working alexandra wonderful neighborhood easy get around ton great restaurants coffee shops stores within walking distance definitely one nicest houses ever chance stay anyone would lucky get experience great home great city', 'alexandra home amazing neat neighbourhood everything described great condition rooms great sizes third floor room sleeping nook outdoor deck fantastic anyone looking quiet neighbourhood short streetcar ride car trip away downtown core stay thanks alexandra', 'beautiful home comfortable clean perfect family families traveling together close amazing restaurents alexandra gave us complete list sorts useful information including nice running routes sporti ones highly highly recommend house kate', 'alexandra incredible host stay beautiful home checked us offered help anyway could house described great neighbourhood everything easy access friends thoroughly enjoyed would recommend everyone say thank']\n"
     ]
    }
   ],
   "source": [
    "print(all_reviews[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790137c1-0c04-429c-b5a7-1c1ef1dae311",
   "metadata": {},
   "source": [
    "Next, we will vectorize the reviews. We will create functions to convert reviews into their vector representations by averaging the vectors of the words they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "240d6682-675d-4c6a-b9d4-05f0f707f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318895c8-66d6-4728-9ca2-52bbc58c0a88",
   "metadata": {},
   "source": [
    "Next, we will convert the review text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42161454-1a0a-4d01-9c49-f086ed352432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10769 entries, 0 to 10768\n",
      "Columns: 501 entries, listing_id to tfidf_499\n",
      "dtypes: float64(501)\n",
      "memory usage: 41.2 MB\n"
     ]
    }
   ],
   "source": [
    "reviews_tfidf_avg.info()\n",
    "reviews_tfidf_avg.to_csv('reviews_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95e5812c-45da-42bd-a712-3db1f11a0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14866 entries, 0 to 14865\n",
      "Columns: 501 entries, listing_id to count_499\n",
      "dtypes: float64(500), int64(1)\n",
      "memory usage: 56.8 MB\n"
     ]
    }
   ],
   "source": [
    "reviews_count_avg.info()\n",
    "reviews_count_avg.to_csv('reviews_countvec.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ccc1de-70e2-4436-9b5d-b408aa35068f",
   "metadata": {},
   "source": [
    "Now we will create the predictive model using these features from reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88c06a6f-92da-4e0e-b2e5-819899cebdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the review features into a single DataFrame using inner join to ensure only listings present in both datasets are kept\n",
    "reviews_features_combined = reviews_tfidf_avg.merge(reviews_count_avg, on=\"listing_id\", how=\"inner\")\n",
    "                                     \n",
    "\n",
    "# Merge the combined features dataframe with the `review_scores_rating` column from the `listings` dataframe using inner join\n",
    "reviews_data_for_modeling = reviews_features_combined.merge(listings[['listing_id', 'review_scores_rating']], on=\"listing_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "224036c6-1868-4e66-b7b7-2e6c2590e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10769 entries, 0 to 10768\n",
      "Columns: 1001 entries, listing_id to count_499\n",
      "dtypes: float64(1001)\n",
      "memory usage: 82.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10367 entries, 0 to 10366\n",
      "Columns: 1002 entries, listing_id to review_scores_rating\n",
      "dtypes: float64(1002)\n",
      "memory usage: 79.3 MB\n"
     ]
    }
   ],
   "source": [
    "reviews_features_combined.info()\n",
    "reviews_data_for_modeling.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "057fccd3-b8d5-49e8-b735-4c6d0791a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data For Modeling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define reviews features and target variable\n",
    "X_reviews = reviews_data_for_modeling.drop(['listing_id', 'review_scores_rating'], axis=1)\n",
    "y_reviews = reviews_data_for_modeling['review_scores_rating']\n",
    "\n",
    "# Split the reviews data into training and testing sets\n",
    "X_reviews_train, X_reviews_test, y_reviews_train, y_reviews_test = train_test_split(X_reviews, y_reviews, test_size=0.2, random_state=42)\n",
    "\n",
    "# Capture feature names from the training data\n",
    "feature_names_reviews = X_reviews_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "288189e0-6690-4f1b-a34b-8dae97b05763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost training time:  10.00 seconds\n",
      "XGBoost testing time: 0.16 seconds\n"
     ]
    }
   ],
   "source": [
    "# XGB Model Training\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "# Start timing XGBoost training\n",
    "start_xgb_train_time = time.time()\n",
    "\n",
    "# Fit the XGB model to the reviews training data\n",
    "xgb_model.fit(X_reviews_train, y_reviews_train)\n",
    "\n",
    "# End timing XGBoost model\n",
    "end_xgb_train_time = time.time()\n",
    "xgb_training_time = end_xgb_train_time - start_xgb_train_time\n",
    "print(f\"XGBoost training time: {xgb_training_time: .2f} seconds\")\n",
    "\n",
    "# Start timing XGBoost prediction(testing)\n",
    "start_xgb_test_time = time.time()\n",
    "\n",
    "# Predict ratings on the test set\n",
    "xgb_predictions_reviews = xgb_model.predict(X_reviews_test)\n",
    "\n",
    "# End XGBoost prediction(testing)\n",
    "end_xgb_test_time = time.time()\n",
    "xgb_testing_time = end_xgb_test_time - start_xgb_test_time\n",
    "print(f\"XGBoost testing time: {xgb_testing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4e55d26-bba6-4340-804a-c39ca453cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Mean Squared Error (MSE): 0.08877656203231299\n",
      "XGB R-squared (R2): 0.22162347143626204\n",
      "XGB Test RMSE: 0.30\n"
     ]
    }
   ],
   "source": [
    "# XGB Model Evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate the performance metrics\n",
    "mse_xgb_reviews = mean_squared_error(y_reviews_test, xgb_predictions_reviews)\n",
    "r2_xgb_reviews = r2_score(y_reviews_test, xgb_predictions_reviews)\n",
    "rmse_xgb_reviews = np.sqrt(mse_xgb_reviews)\n",
    "\n",
    "print(f\"XGB Mean Squared Error (MSE): {mse_xgb_reviews}\")\n",
    "print(f\"XGB R-squared (R2): {r2_xgb_reviews}\")\n",
    "print(f\"XGB Test RMSE: {rmse_xgb_reviews:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b48ed0f-d8ab-47ad-ae43-3e7eb0fa4706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_213    0.020698\n",
      "count_13     0.018728\n",
      "count_112    0.015958\n",
      "count_113    0.012877\n",
      "count_61     0.011612\n",
      "               ...   \n",
      "count_103    0.000000\n",
      "count_104    0.000000\n",
      "count_105    0.000000\n",
      "tfidf_297    0.000000\n",
      "count_0      0.000000\n",
      "Length: 1000, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#  xgb_model is the trained XGBoost model\n",
    "xgb_feature_importances_reviews = xgb_model.feature_importances_\n",
    "\n",
    "# Create a pandas Series to hold the feature importances with the feature names as the index\n",
    "xgb_importances_reviews = pd.Series(xgb_feature_importances_reviews, index=feature_names_reviews)\n",
    "\n",
    "# print the sorted xgb features based on importance\n",
    "print(xgb_importances_reviews.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e6993-9012-432f-88e2-74fc8a13e640",
   "metadata": {},
   "source": [
    "Now I will build a Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28fd7841-6827-49f8-9e6a-598de7473a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training time  1169.86 seconds\n",
      "Random Forest testing time:  0.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest Model Training\n",
    "\n",
    "# Initialize Random Forest Model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Start training Random Forest training\n",
    "start_rf_train_time = time.time()\n",
    "\n",
    "# Fir the Random Forest model to the reviews training data\n",
    "rf_model.fit(X_reviews_train, y_reviews_train)\n",
    "\n",
    "# end timing Random Forest training\n",
    "end_rf_train_time = time.time()\n",
    "rf_training_time = end_rf_train_time - start_rf_train_time\n",
    "print(f\"Random Forest training time {rf_training_time: .2f} seconds\")\n",
    "\n",
    "# Random Forest Model Testing\n",
    "\n",
    "# Start timing Random Forest Testing\n",
    "start_rf_test_time = time.time()\n",
    "\n",
    "# predict ratings on the test set\n",
    "rf_predictions_reviews = rf_model.predict(X_reviews_test)\n",
    "\n",
    "# End timing Random Forest testing\n",
    "end_rf_test_time=time.time()\n",
    "rf_testing_time = end_rf_test_time - start_rf_test_time\n",
    "print(f\"Random Forest testing time: {rf_testing_time: .2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8a4bc46-31de-4a32-bb00-cabe18ee8579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Squared Error (MSE): 0.09439652561716488\n",
      "Random Firest R-squared (R2): 0.17234866685169814\n",
      "Random Forest Test RMSE: 0.31\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model Evaluation\n",
    "mse_rf_reviews = mean_squared_error(y_reviews_test, rf_predictions_reviews)\n",
    "r2_rf_reviews = r2_score(y_reviews_test, rf_predictions_reviews)\n",
    "rmse_rf_reviews = np.sqrt(mse_rf_reviews)\n",
    "\n",
    "print(f\"Random Forest Mean Squared Error (MSE): {mse_rf_reviews}\")\n",
    "print(f\"Random Firest R-squared (R2): {r2_rf_reviews}\")\n",
    "print(f\"Random Forest Test RMSE: {rmse_rf_reviews:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cee9fd7-57ac-41cd-b42a-07944795f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_213    0.053668\n",
      "count_13     0.027943\n",
      "count_61     0.023659\n",
      "count_226    0.021601\n",
      "tfidf_192    0.020579\n",
      "               ...   \n",
      "count_90     0.000025\n",
      "count_331    0.000025\n",
      "tfidf_391    0.000023\n",
      "tfidf_322    0.000021\n",
      "count_91     0.000020\n",
      "Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyzing Random Forest feature Importances\n",
    "rf_feature_importances_reviews = rf_model.feature_importances_\n",
    "rf_importances_reviews = pd.Series(rf_feature_importances_reviews, index=feature_names_reviews).sort_values(ascending=False)\n",
    "\n",
    "print(rf_importances_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132baaa5-bac2-4e41-91f3-ab63870829eb",
   "metadata": {},
   "source": [
    "Now I will use an lgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d15f0f57-c9a0-42bf-9d42-bd0b466b13ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.11.4)\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.3 MB 262.6 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.3 MB 525.1 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.2/1.3 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.5/1.3 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.1/1.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 252470\n",
      "[LightGBM] [Info] Number of data points in the train set: 8293, number of used features: 1000\n",
      "[LightGBM] [Info] Start training from score 4.763080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LGBM training time: 3.35 seconds\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "LGBM testing time: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize the LGBM regressor\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "# Start timing LGBM training\n",
    "start_lgb_train_time = time.time()\n",
    "\n",
    "# Fit the LGBM model to the reviews training data\n",
    "lgb_model.fit(X_reviews_train, y_reviews_train)\n",
    "\n",
    "# End timing LGBM training\n",
    "end_lgb_train_time = time.time()\n",
    "lgb_training_time = end_lgb_train_time - start_lgb_train_time\n",
    "print(f\"LGBM training time: {lgb_training_time:.2f} seconds\")\n",
    "\n",
    "# Start timing LGBM prediction (testing)\n",
    "start_lgb_test_time = time.time()\n",
    "\n",
    "# Predict ratings on the test set\n",
    "lgb_predictions_reviews = lgb_model.predict(X_reviews_test)\n",
    "\n",
    "# End timing LGBM prediction (testing)\n",
    "end_lgb_test_time = time.time()\n",
    "lgb_testing_time = end_lgb_test_time - start_lgb_test_time\n",
    "print(f\"LGBM testing time: {lgb_testing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c007ad3b-064a-41c9-bb6e-5ec21b8ef309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Mean Squared Error (MSE): 0.08528812688050662\n",
      "LGBM R-squared (R2): 0.25220942770019616\n",
      "LGBM Test RMSE: 0.29\n"
     ]
    }
   ],
   "source": [
    "# LGBM Model Evaluation\n",
    "mse_lgb_reviews = mean_squared_error(y_reviews_test, lgb_predictions_reviews)\n",
    "r2_lgb_reviews = r2_score(y_reviews_test, lgb_predictions_reviews)\n",
    "rmse_lgb_reviews = np.sqrt(mse_lgb_reviews)\n",
    "\n",
    "print(f\"LGBM Mean Squared Error (MSE): {mse_lgb_reviews}\")\n",
    "print(f\"LGBM R-squared (R2): {r2_lgb_reviews}\")\n",
    "print(f\"LGBM Test RMSE: {rmse_lgb_reviews:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c893789-da45-4dcb-b162-04ddd89ce1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_190    64\n",
      "count_226    56\n",
      "count_144    42\n",
      "count_402    35\n",
      "count_362    33\n",
      "             ..\n",
      "tfidf_357     0\n",
      "tfidf_358     0\n",
      "tfidf_359     0\n",
      "tfidf_360     0\n",
      "count_499     0\n",
      "Length: 1000, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Analyzing LGBM Feature Importances\n",
    "lgb_feature_importances_reviews = lgb_model.feature_importances_\n",
    "lgb_importances_reviews = pd.Series(lgb_feature_importances_reviews, index=feature_names_reviews).sort_values(ascending=False)\n",
    "\n",
    "print(lgb_importances_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46358bc-af04-47f7-bc3c-5b19407cfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2baf6ec6-f0c1-44fa-a3d9-7da346f7154e",
   "metadata": {},
   "source": [
    "Now we will prepare the listings dataset (feature extraction, encoding etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b174c73-756f-4d58-875c-65ac198f21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv(\"http://data.insideairbnb.com/canada/on/toronto/2024-02-14/data/listings.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "752d7e26-52a9-4a23-ab50-23207502131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.rename(columns={'id': 'listing_id'}, inplace=True)\n",
    "listings.rename(columns={'name': 'listing_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eeaea38a-9fc4-457a-8bb2-6e8749beab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  filter the listings and reviews datasets to include only common listings\n",
    "listings = listings[listings['listing_id'].isin(reviews['listing_id'])]\n",
    "reviews = reviews[reviews['listing_id'].isin(listings['listing_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfda33a-24d5-4aa5-9352-8e98b85b384c",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bb32a01-155a-4bf1-9662-7a3a91f04071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listings.drop('listing_url', axis=1, inplace=True)\n",
    "listings.drop('picture_url', axis=1, inplace=True)\n",
    "\n",
    "listings.drop('host_name', axis=1, inplace=True)\n",
    "listings.drop('host_neighbourhood', axis=1, inplace=True)\n",
    "listings.drop('host_picture_url', axis=1, inplace=True)\n",
    "\n",
    "listings.drop('host_thumbnail_url', axis=1, inplace=True)\n",
    "listings.drop('host_url', axis=1, inplace=True)\n",
    "\n",
    "listings.drop('scrape_id', axis=1, inplace=True)\n",
    "listings.drop('last_scraped', axis=1, inplace=True)\n",
    "listings.drop('source', axis=1, inplace=True)\n",
    "listings.drop('calendar_last_scraped', axis=1, inplace=True)\n",
    "listings.drop('calendar_updated', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af65e896-ab2f-4882-aaa3-b63a339f0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.drop('host_location', axis=1, inplace=True)\n",
    "listings.drop('neighbourhood_group_cleansed', axis=1, inplace=True)\n",
    "listings.drop('neighbourhood', axis=1, inplace=True)\n",
    "listings.drop('license', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f034c935-46bd-45a0-abca-0b3cee33cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.drop('listing_url', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198de56-8068-49ca-8da1-88f3ed6269ab",
   "metadata": {},
   "source": [
    "Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec582096-7a97-4942-9766-ab93743c32b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial count of listings with missing 'review_scores_rating': 2\n",
      "Shape of listings after dropping those missing 'review_scores_rating': (14136, 59)\n",
      "Final shape of listings after dropping any with missing review scores: (14131, 59)\n",
      "Final check - missing review scores:\n",
      "review_scores_rating           0\n",
      "review_scores_accuracy         0\n",
      "review_scores_cleanliness      0\n",
      "review_scores_checkin          0\n",
      "review_scores_communication    0\n",
      "review_scores_location         0\n",
      "review_scores_value            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display count of listings with missing 'review_scores_rating' before any operations\n",
    "print(f\"Initial count of listings with missing 'review_scores_rating': {listings['review_scores_rating'].isnull().sum()}\")\n",
    "\n",
    "# Drop listings with missing 'review_scores_rating'\n",
    "listings.dropna(subset=['review_scores_rating'], inplace=True)\n",
    "\n",
    "# Display shape of the DataFrame after dropping listings with missing 'review_scores_rating'\n",
    "print(f\"Shape of listings after dropping those missing 'review_scores_rating': {listings.shape}\")\n",
    "\n",
    "# Now, check and drop listings with any missing review score details\n",
    "review_score_columns = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                        'review_scores_communication', 'review_scores_location', 'review_scores_value']\n",
    "\n",
    "# Drop listings with any missing review scores\n",
    "listings.dropna(subset=review_score_columns, inplace=True)\n",
    "\n",
    "# Display final shape of the DataFrame after all drop operations\n",
    "print(f\"Final shape of listings after dropping any with missing review scores: {listings.shape}\")\n",
    "\n",
    "# Display the count of missing values for each review score column as a final check\n",
    "missing_review_scores_final_check = listings[review_score_columns].isnull().sum()\n",
    "print(\"Final check - missing review scores:\")\n",
    "print(missing_review_scores_final_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd51aac4-afc9-43cb-8b0c-8017f2e0121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bathrooms bathrooms_text\n",
      "1260         1.0         1 bath\n",
      "2609         1.0  1 shared bath\n",
      "13723        2.0        2 baths\n"
     ]
    }
   ],
   "source": [
    "# Directly fill missing 'bathrooms_text' for the identified rows\n",
    "listings.loc[listings['bathrooms'] == 0.0, 'bathrooms_text'] = listings.loc[listings['bathrooms'] == 0.0, 'bathrooms_text'].fillna('0 baths')\n",
    "listings.loc[listings['bathrooms'] == 1.0, 'bathrooms_text'] = listings.loc[listings['bathrooms'] == 1.0, 'bathrooms_text'].fillna('1 bath')\n",
    "\n",
    "# Check the previously missing values to ensure they've been filled\n",
    "print(listings.loc[[1260, 2609, 13723], ['bathrooms', 'bathrooms_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "399db699-45ad-42fc-91e5-9b4befefb7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829    1.0\n",
      "Name: host_total_listings_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Identify the index of the row with the missing 'host_total_listings_count'\n",
    "missing_index = listings[listings['host_total_listings_count'].isnull()].index\n",
    "\n",
    "# Sum the specific listings counts for that index\n",
    "total_calculated = listings.loc[missing_index, ['calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms']].sum(axis=1)\n",
    "\n",
    "# Impute the missing 'host_total_listings_count' with the calculated total\n",
    "listings.loc[missing_index, 'host_total_listings_count'] = total_calculated\n",
    "\n",
    "# Verify the operation\n",
    "print(listings.loc[missing_index, 'host_total_listings_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b24f7-8e53-4877-8e87-20041897be2d",
   "metadata": {},
   "source": [
    "Get rid of special characters($,%) /convert to correct datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f2c010d-cfaf-4422-b5b2-03ebaab88bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2    164.0\n",
       "3      NaN\n",
       "4      NaN\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert price to numeric\n",
    "listings['price'] = listings['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "listings['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "884e2d1b-14d8-4ca4-b5ea-cecc28fbd061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    41%\n",
      "3    75%\n",
      "4    NaN\n",
      "Name: host_acceptance_rate, dtype: object\n",
      "0     NaN\n",
      "1     NaN\n",
      "2    41.0\n",
      "3    75.0\n",
      "4     NaN\n",
      "Name: host_acceptance_rate, dtype: float64\n",
      "0     NaN\n",
      "1     NaN\n",
      "2    100%\n",
      "3    100%\n",
      "4     NaN\n",
      "Name: host_response_rate, dtype: object\n",
      "0      NaN\n",
      "1      NaN\n",
      "2    100.0\n",
      "3    100.0\n",
      "4      NaN\n",
      "Name: host_response_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# host acceptance rate is a percentage, lets fix that\n",
    "print(listings['host_acceptance_rate'].head())\n",
    "\n",
    "# convert to percentage(float)\n",
    "listings['host_acceptance_rate'] = listings['host_acceptance_rate'].str.replace('%','').astype(float)\n",
    "print(listings['host_acceptance_rate'].head())\n",
    "\n",
    "# host response rate is a percentage, it seems to be read as text so lets fix that\n",
    "print(listings['host_response_rate'].head())\n",
    "\n",
    "#convert host response rate to percentage(float)\n",
    "listings['host_response_rate'] = listings['host_response_rate'].str.replace('%','').astype(float)\n",
    "print(listings['host_response_rate'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3cde20-f58b-4902-a4da-cea2c49faeea",
   "metadata": {},
   "source": [
    "Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f21303e3-95cd-47af-b6e3-954dd181a794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_time      0\n",
      "host_response_rate      0\n",
      "host_acceptance_rate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For numerical columns\n",
    "listings['host_response_rate'] = listings['host_response_rate'].fillna(listings['host_response_rate'].median())\n",
    "listings['host_acceptance_rate'] = listings['host_acceptance_rate'].fillna(listings['host_acceptance_rate'].median())\n",
    "\n",
    "# For categorical columns\n",
    "listings['host_response_time'] = listings['host_response_time'].fillna(listings['host_response_time'].mode()[0])\n",
    "\n",
    "# Confirm the imputation\n",
    "print(listings[['host_response_time', 'host_response_rate', 'host_acceptance_rate']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "026f7af8-75f7-41a6-99ba-8b4bef8b029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'price' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Attempt to impute missing prices based on the median price for listings with the same 'room_type' and 'accommodates' number\n",
    "listings['price'] = listings.groupby(['room_type', 'accommodates'])['price'] \\\n",
    "                             .transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# For listings where the price is still missing, use the median price of their specific room type as a fallback\n",
    "listings['price'] = listings.groupby(['room_type'])['price'] \\\n",
    "                             .transform(lambda x: x.fillna(x.median()))\n",
    "# If there are still missing values after these steps, use the overall median price as a last resort\n",
    "overall_median_price = listings['price'].median()\n",
    "listings['price'].fillna(overall_median_price, inplace=True)\n",
    "\n",
    "# Check if there are still any missing values in 'price'\n",
    "print(\"Missing values in 'price' after imputation:\", listings['price'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc8458b6-8aa6-4a63-b368-682b841c13dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3560\n"
     ]
    }
   ],
   "source": [
    "print(listings['bathrooms'].isnull().sum())\n",
    "listings['bathrooms'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50965993-aaa0-4786-89ce-366e9203614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of listings with null values for bedrooms: 1103\n",
      "Median:  1.0\n",
      "\n",
      "Count of Each Property Type for Listings with Null Bedrooms:\n",
      "property_type\n",
      "Private room in home                 428\n",
      "Private room in rental unit          197\n",
      "Entire rental unit                   108\n",
      "Private room in condo                101\n",
      "Private room in townhouse             68\n",
      "Entire condo                          51\n",
      "Private room in bungalow              45\n",
      "Entire guest suite                    20\n",
      "Private room in villa                 19\n",
      "Shared room in rental unit            11\n",
      "Entire loft                           11\n",
      "Private room in guest suite            9\n",
      "Entire home                            8\n",
      "Shared room in home                    5\n",
      "Shared room in condo                   3\n",
      "Entire bungalow                        3\n",
      "Entire townhouse                       3\n",
      "Private room in cottage                2\n",
      "Shared room in bungalow                2\n",
      "Private room in guesthouse             2\n",
      "Private room in bed and breakfast      2\n",
      "Shared room in townhouse               2\n",
      "Private room in floor                  1\n",
      "Shared room in guesthouse              1\n",
      "Private room in tiny home              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of listings with null values for bedrooms:', listings['bedrooms'].isnull().sum())\n",
    "print('Median: ', listings['bedrooms'].median())\n",
    "\n",
    "# Filter to listings with null 'bedrooms'\n",
    "listings_with_null_bedrooms = listings[listings['bedrooms'].isnull()]\n",
    "\n",
    "# to see the count of each property type\n",
    "print(\"\\nCount of Each Property Type for Listings with Null Bedrooms:\")\n",
    "print(listings_with_null_bedrooms['property_type'].value_counts())\n",
    "\n",
    "listings['bedrooms'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22ad31b2-ed4d-4af4-9be9-14bc20791829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of listings with null beds values:  3575\n",
      "Median:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Number of listings with null beds values: ',  listings['beds'].isnull().sum())\n",
    "print('Median: ', listings['beds'].median())\n",
    "listings['beds'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f07a8-2193-4f2b-9e81-98f39f4e2e40",
   "metadata": {},
   "source": [
    "Extract number of (amenities, verfications etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f006abe2-7bf1-4f95-b5f8-c85332b5b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['number_of_amenities'] = listings['amenities'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "# listings.drop('amenities', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4473a720-e83c-4d70-a0bb-068af7b8d691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(listings['host_verifications'].isnull().sum())\n",
    "listings.dropna(subset=['host_verifications'], inplace=True)\n",
    "\n",
    "listings['number_of_host_verifications'] = listings['host_verifications'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "listings.drop('host_verifications', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05a1e0f7-ccd8-4829-a465-e27a09d5d87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT\n"
     ]
    }
   ],
   "source": [
    "# Identify the listing with missing 'host_since'\n",
    "missing_host_since_listing = listings[listings['host_since'].isna()]\n",
    "\n",
    "# Assuming 'listing_id' is the common column between 'listings' and 'reviews'\n",
    "# and 'date' is the column in 'reviews' that contains the review dates\n",
    "earliest_review_date = reviews[reviews['listing_id'].isin(missing_host_since_listing['listing_id'])]['date'].min()\n",
    "print(earliest_review_date)\n",
    "\n",
    "# Impute the missing 'host_since' value\n",
    "if pd.notnull(earliest_review_date):\n",
    "    listings.loc[listings['host_since'].isna(), 'host_since'] = earliest_review_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc1ef7bf-43ad-4dcb-b9e8-7a70d0caa9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first_review  Days_since_first_review\n",
      "0   2015-07-19                     3179\n",
      "1   2009-08-20                     5338\n",
      "2   2011-01-05                     4835\n",
      "3   2012-01-26                     4449\n",
      "4   2012-07-05                     4288\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'first_review' is in datetime format\n",
    "listings['first_review'] = pd.to_datetime(listings['first_review'])\n",
    "\n",
    "# Choose a reference date as current date, for example, today's date or a specific recent date\n",
    "current_date = pd.to_datetime('2024-04-01')  # Example current date, adjust as needed\n",
    "\n",
    "# Calculate the difference in days between the current date and the first review\n",
    "listings['Days_since_first_review'] = (current_date - listings['first_review']).dt.days\n",
    "\n",
    "# Verify the new column\n",
    "print(listings[['first_review', 'Days_since_first_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56537360-5bc0-40ba-bd6f-114cf885517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  last_review  Days_since_last_review\n",
      "0  2017-08-07                    2429\n",
      "1  2013-08-27                    3870\n",
      "2  2023-09-01                     213\n",
      "3  2022-05-28                     674\n",
      "4  2023-01-31                     426\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'last_review' is in datetime format\n",
    "listings['last_review'] = pd.to_datetime(listings['last_review'])\n",
    "\n",
    "# Use a reference date as the current date, adjust as necessary\n",
    "current_date = pd.to_datetime('2024-04-01')  # Example current date, adjust as needed\n",
    "\n",
    "# Calculate the difference in days between the current date and the last review\n",
    "listings['Days_since_last_review'] = (current_date - listings['last_review']).dt.days\n",
    "\n",
    "# Verify the new column\n",
    "print(listings[['last_review', 'Days_since_last_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0bf82-951c-43ff-bff0-c65a25e0a5fa",
   "metadata": {},
   "source": [
    "Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "544d21e2-ecdb-4ce3-807e-5efb975393ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "has_availability\n",
      "t    14102\n",
      "f       14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(listings['has_availability'].isnull().sum())\n",
    "\n",
    "print(listings['has_availability'].value_counts())\n",
    "\n",
    "listings['has_availability'].fillna(0, inplace=True)\n",
    "listings['has_availability'].loc[listings['has_availability'] == 't'] = 1\n",
    "listings['has_availability'].loc[listings['has_availability'] == 'f'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d7956ae-fe0f-4610-b2cf-9329ac839e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to convert\n",
    "columns_to_encode = [\n",
    "    'host_is_superhost',\n",
    "    'host_has_profile_pic',\n",
    "    'host_identity_verified',\n",
    "    'has_availability',\n",
    "    'instant_bookable'\n",
    "]\n",
    "\n",
    "# Convert 't' to 1 and 'f' to 0\n",
    "for column in columns_to_encode:\n",
    "    listings[column] = listings[column].apply(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2fbc1198-2021-4813-8b10-9c4557269aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         room_type  bathroom_count  bathroom_privacy_encoded\n",
      "0  Entire home/apt             3.0                         1\n",
      "1     Private room             1.5                         2\n",
      "2  Entire home/apt             1.0                         1\n",
      "3  Entire home/apt             1.0                         1\n",
      "4     Private room             1.0                         2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Assuming 'listings' is your DataFrame and it already contains 'bathrooms_text' and 'room_type'\n",
    "\n",
    "# Function to extract bathroom count\n",
    "def extract_bathroom_count(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    if 'half-bath' in text.lower() or 'shared half-bath' in text.lower() or 'private half-bath' in text.lower():\n",
    "        return 0.5\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)', text)  # Match a decimal number\n",
    "    return float(match.group()) if match else None\n",
    "\n",
    "# Modified function to extract bathroom privacy and infer from room type if not specified, with direct encoding\n",
    "def extract_bathroom_privacy_encoded(row):\n",
    "    text = row['bathrooms_text']\n",
    "    room_type = row['room_type']\n",
    "    privacy_encoded = 0  # Default to 0 for 'Not Specified'\n",
    "    if pd.isna(text):\n",
    "        return privacy_encoded\n",
    "    if 'private' in text.lower():\n",
    "        privacy_encoded = 1  # Encode 'Private' as 1\n",
    "    elif 'shared' in text.lower():\n",
    "        privacy_encoded = 2  # Encode 'Shared' as 2\n",
    "\n",
    "    # Infer privacy based on room type if not explicitly mentioned\n",
    "    if privacy_encoded == 0:\n",
    "        if room_type in ['Private room', 'Shared room']:\n",
    "            privacy_encoded = 2  # Shared\n",
    "        elif room_type == 'Entire home/apt':\n",
    "            privacy_encoded = 1  # Private\n",
    "\n",
    "    return privacy_encoded\n",
    "\n",
    "# Apply the functions\n",
    "listings['bathroom_count'] = listings['bathrooms_text'].apply(extract_bathroom_count)\n",
    "listings['bathroom_privacy_encoded'] = listings.apply(extract_bathroom_privacy_encoded, axis=1)\n",
    "\n",
    "# Now you can drop the original 'bathrooms_text' column if you wish, as its information has been encoded into two new columns\n",
    "# listings.drop('bathrooms_text', axis=1, inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(listings[['room_type', 'bathroom_count', 'bathroom_privacy_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3aa90832-1232-40ff-9a36-c2ae8b23233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_response_time_mapping = {\n",
    "    'within an hour': 1,\n",
    "    'within a few hours': 2,\n",
    "    'within a day': 3,\n",
    "    'a few days or more': 4\n",
    "}\n",
    "listings['host_response_time_encoded'] = listings['host_response_time'].map(host_response_time_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52281fe8-9544-42de-9974-7c53423450fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    2\n",
      "2    0\n",
      "3    0\n",
      "4    2\n",
      "Name: room_type_encoded, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "room_type_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "listings['room_type_encoded'] = room_type_encoder.fit_transform(listings['room_type'])\n",
    "\n",
    "print(listings['room_type_encoded'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0223fe5-5677-4061-bafd-90479b7db8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property_category_numeric\n",
      "3    9543\n",
      "2    3416\n",
      "1    1154\n",
      "0      17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def categorize_property_type_numeric(property_type):\n",
    "    unique_luxury = ['treehouse', 'island', 'shipping container', 'tiny home', 'camper', 'castle', 'hut', 'barn', 'boat']\n",
    "    house_villa = ['house', 'villa', 'cottage', 'bungalow', 'townhouse']\n",
    "    apartment_condo = ['apartment', 'condo', 'loft', 'serviced apartment']\n",
    "\n",
    "    # Ensure the property type is in lowercase and strip any leading/trailing whitespace\n",
    "    property_type_lower = property_type.lower().strip()\n",
    "\n",
    "    # Numeric categories\n",
    "    category_mapping = {\n",
    "        'Unique/Luxury Stay': 0,\n",
    "        'House/Villa': 1,\n",
    "        'Apartment/Condo': 2,\n",
    "        'Others': 3\n",
    "    }\n",
    "\n",
    "    # Check for unique/luxury stays\n",
    "    if any(unique in property_type_lower for unique in unique_luxury):\n",
    "        return category_mapping['Unique/Luxury Stay']\n",
    "\n",
    "    # Check for house/villa\n",
    "    elif any(house in property_type_lower for house in house_villa):\n",
    "        return category_mapping['House/Villa']\n",
    "\n",
    "    # Check for apartment/condo\n",
    "    elif any(apartment in property_type_lower for apartment in apartment_condo):\n",
    "        return category_mapping['Apartment/Condo']\n",
    "\n",
    "    # Default to Others\n",
    "    else:\n",
    "        return category_mapping['Others']\n",
    "\n",
    "# Apply the numeric categorization function\n",
    "listings['property_category_numeric'] = listings['property_type'].apply(categorize_property_type_numeric)\n",
    "\n",
    "# Check the distribution of the new property_category_numeric column\n",
    "print(listings['property_category_numeric'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51313c05-1e60-453f-bf17-8ba41ada398f",
   "metadata": {},
   "source": [
    "Create new features based on means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7090607b-611d-4c5a-bd66-ae9de2a72fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean review scores for each 'accommodates' value\n",
    "temp = listings.groupby('accommodates')[['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].mean().reset_index()\n",
    "\n",
    "# Rename columns to indicate these are mean values (adapted for clarity)\n",
    "temp.columns = ['accommodates'] + [('mean_accommodates_' + c) for c in temp.columns[1:]]\n",
    "\n",
    "# Merge these mean scores back into the main 'listings' DataFrame\n",
    "listings = listings.merge(temp, on='accommodates', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff0281a5-8aa1-438a-b07a-9bbce9840e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean review scores grouped by 'host_response_time'\n",
    "temp = listings.groupby('host_response_time')[['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].mean().reset_index()\n",
    "\n",
    "# Rename columns to indicate these are mean values, adapting for clarity\n",
    "temp.columns = ['host_response_time'] + [('mean_host_response_time_' + c) for c in temp.columns[1:]]\n",
    "\n",
    "# Merge these mean scores back into the main 'listings' DataFrame\n",
    "listings = listings.merge(temp, on='host_response_time', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039fda6-e4a9-4fa7-8b6f-4e9af1577774",
   "metadata": {},
   "source": [
    "Sentiment score for text columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1275bc45-e57c-4148-b579-8530249caff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cccd26a-055f-4d0f-869c-a57ca24506c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14130/14130 [00:01<00:00, 9331.48it/s] \n",
      "100%|██████████| 14130/14130 [00:00<00:00, 571807.07it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 577113.49it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 706787.14it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 570079.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.8398\n",
      "1    0.0000\n",
      "2    0.0000\n",
      "3    0.2732\n",
      "4    0.0000\n",
      "Name: name_compound, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(listings['listing_name'].isnull().sum())\n",
    "\n",
    "listings['listing_name_sentiment'] = listings['listing_name'].progress_apply(lambda x: sid.polarity_scores(x))\n",
    "\n",
    "listings['name_compound'] = listings['listing_name_sentiment'].progress_apply(lambda x: x['compound'])\n",
    "listings['name_neg'] = listings['listing_name_sentiment'].progress_apply(lambda x: x['neg'])\n",
    "listings['name_neu'] = listings['listing_name_sentiment'].progress_apply(lambda x: x['neu'])\n",
    "listings['name_pos'] = listings['listing_name_sentiment'].progress_apply(lambda x: x['pos'])\n",
    "\n",
    "print(listings['name_compound'].head())\n",
    "\n",
    "listings.drop('listing_name', axis=1, inplace=True)\n",
    "listings.drop('listing_name_sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aac3655d-3cc1-4990-a591-3137bb8bc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14130/14130 [00:13<00:00, 1051.98it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 430749.38it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 637702.46it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 706273.35it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 694764.73it/s]\n"
     ]
    }
   ],
   "source": [
    "print(listings['description'].isnull().sum())\n",
    "listings['description'].fillna('none', inplace=True)\n",
    "\n",
    "listings['description_sentiment'] = listings['description'].progress_apply(lambda x: sid.polarity_scores(x))\n",
    "\n",
    "listings['description_compound'] = listings['description_sentiment'].progress_apply(lambda x: x['compound'])\n",
    "listings['description_neg'] = listings['description_sentiment'].progress_apply(lambda x: x['neg'])\n",
    "listings['description_neu'] = listings['description_sentiment'].progress_apply(lambda x: x['neu'])\n",
    "listings['description_pos'] = listings['description_sentiment'].progress_apply(lambda x: x['pos'])\n",
    "\n",
    "listings.drop('description', axis=1, inplace=True)\n",
    "listings.drop('description_sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "753cda7a-0c27-4e19-a7bd-01077389fba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14130/14130 [00:06<00:00, 2324.00it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 740162.05it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 781186.77it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 780991.18it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 795339.46it/s]\n"
     ]
    }
   ],
   "source": [
    "print(listings['host_about'].isnull().sum())\n",
    "listings['host_about'].fillna('none', inplace=True)\n",
    "\n",
    "listings['host_about_sentiment'] = listings['host_about'].progress_apply(lambda x: sid.polarity_scores(x))\n",
    "\n",
    "listings['hostabout_compound'] = listings['host_about_sentiment'].progress_apply(lambda x: x['compound'])\n",
    "listings['hostabout_neg'] = listings['host_about_sentiment'].progress_apply(lambda x: x['neg'])\n",
    "listings['hostabout_neu'] = listings['host_about_sentiment'].progress_apply(lambda x: x['neu'])\n",
    "listings['hostabout_pos'] = listings['host_about_sentiment'].progress_apply(lambda x: x['pos'])\n",
    "\n",
    "listings.drop('host_about', axis=1, inplace=True)\n",
    "listings.drop('host_about_sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "363ae084-2e8d-4361-9075-346507fd1728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14130/14130 [00:07<00:00, 1853.54it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 532666.28it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 486137.56it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 642096.59it/s]\n",
      "100%|██████████| 14130/14130 [00:00<00:00, 532283.55it/s]\n"
     ]
    }
   ],
   "source": [
    "print(listings['neighborhood_overview'].isnull().sum())\n",
    "listings['neighborhood_overview'].fillna('none', inplace=True)\n",
    "\n",
    "listings['neighborhood_overview_sentiment'] = listings['neighborhood_overview'].progress_apply(lambda x: sid.polarity_scores(x))\n",
    "\n",
    "listings['neighborhood_overview_compound'] = listings['neighborhood_overview_sentiment'].progress_apply(lambda x: x['compound'])\n",
    "listings['neighborhood_overview_neg'] = listings['neighborhood_overview_sentiment'].progress_apply(lambda x: x['neg'])\n",
    "listings['neighborhood_overview_neu'] = listings['neighborhood_overview_sentiment'].progress_apply(lambda x: x['neu'])\n",
    "listings['neighborhood_overview_pos'] = listings['neighborhood_overview_sentiment'].progress_apply(lambda x: x['pos'])\n",
    "\n",
    "listings.drop('neighborhood_overview', axis=1, inplace=True)\n",
    "listings.drop('neighborhood_overview_sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305ae3e-4a58-4c9b-9803-eff5a9347b24",
   "metadata": {},
   "source": [
    "Now we will create a model using the features from reviews and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945349dc-93fd-415f-9927-2ddd46bd1b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f84208-e830-4603-90c2-585622fb10a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a17ebb-c8b8-4d8d-bd1c-9381b59d3fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911158b7-47e5-44fb-b0ac-68b5e1719fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
